from pydantic import BaseModel, Field, field_validator
from typing import List, Dict, Any
from datetime import datetime
from enum import Enum

# 1. AIè¾“å‡ºç»“æ„åŒ– - æœ€æ ¸å¿ƒçš„åº”ç”¨
class AIAnalysisResult(BaseModel):
    """AIåˆ†æç»“æœç»“æ„åŒ–è¾“å‡º"""
    sentiment: str = Field(description="æƒ…æ„Ÿå€¾å‘: positive/negative/neutral")
    confidence: float = Field(ge=0, le=1, description="ç½®ä¿¡åº¦")
    key_phrases: List[str] = Field(description="å…³é”®çŸ­è¯­åˆ—è¡¨")
    topics: List[str] = Field(description="æ¶‰åŠä¸»é¢˜")
    summary: str = Field(description="å†…å®¹æ‘˜è¦")

    @field_validator('sentiment')
    def validate_sentiment(cls, v):
        allowed = ['positive', 'negative', 'neutral']
        if v not in allowed:
            raise ValueError(f'æƒ…æ„Ÿå€¾å‘å¿…é¡»æ˜¯: {allowed}')
        return v

def ai_structured_output_demo():
    """AIè¾“å‡ºç»“æ„åŒ– - LangChainé›†æˆ"""
    print("ğŸ¯ 1. AIè¾“å‡ºç»“æ„åŒ– (LangChainæ ¸å¿ƒåº”ç”¨)")
    print("=" * 50)

    # æ¨¡æ‹ŸAIçš„åŸå§‹è¾“å‡ºï¼ˆé€šå¸¸æ˜¯ä¸å¯é¢„æµ‹çš„æ–‡æœ¬ï¼‰
    raw_ai_output = """
    è¿™æ˜¯ä¸€æ®µå…³äºäº§å“è¯„è®ºçš„åˆ†æï¼š
    æƒ…æ„Ÿï¼šç§¯ææ­£é¢
    ç½®ä¿¡åº¦ï¼š0.92
    å…³é”®ç‚¹ï¼šè´¨é‡å¾ˆå¥½, é€è´§å¿«, åŒ…è£…ç²¾ç¾
    ä¸»é¢˜ï¼šè´­ç‰©ä½“éªŒ, äº§å“è´¨é‡
    æ‘˜è¦ï¼šç”¨æˆ·å¯¹äº§å“è´¨é‡å’Œé…é€æœåŠ¡éå¸¸æ»¡æ„
    """

    # ä½¿ç”¨Pydanticç»“æ„åŒ–åçš„AIè¾“å‡º
    structured_output = AIAnalysisResult(
        sentiment="positive",
        confidence=0.92,
        key_phrases=["è´¨é‡å¾ˆå¥½", "é€è´§å¿«", "åŒ…è£…ç²¾ç¾"],
        topics=["è´­ç‰©ä½“éªŒ", "äº§å“è´¨é‡"],
        summary="ç”¨æˆ·å¯¹äº§å“è´¨é‡å’Œé…é€æœåŠ¡éå¸¸æ»¡æ„"
    )

    print("ğŸ“Š ç»“æ„åŒ–åçš„AIåˆ†æç»“æœ:")
    print(f"æƒ…æ„Ÿ: {structured_output.sentiment}")
    print(f"ç½®ä¿¡åº¦: {structured_output.confidence:.2f}")
    print(f"å…³é”®çŸ­è¯­: {', '.join(structured_output.key_phrases)}")
    print(f"å¯ç¼–ç¨‹ä½¿ç”¨: if result.confidence > 0.8: process_high_confidence()")

# 2. æ™ºèƒ½å¯¹è¯ç³»ç»Ÿ
class DialogState(str, Enum):
    GREETING = "greeting"
    QUESTION = "question"
    COMPLAINT = "complaint"
    SUPPORT = "support"
    CLOSING = "closing"

class ConversationTurn(BaseModel):
    """å¯¹è¯è½®æ¬¡ç»“æ„åŒ–"""
    user_input: str = Field(description="ç”¨æˆ·è¾“å…¥")
    intent: DialogState = Field(description="å¯¹è¯æ„å›¾")
    entities: Dict[str, Any] = Field(description="æå–çš„å®ä½“")
    response: str = Field(description="AIå›å¤")
    timestamp: datetime = Field(default_factory=datetime.now)

    def to_chat_history(self):
        """è½¬æ¢ä¸ºèŠå¤©å†å²æ ¼å¼"""
        return {
            "role": "user",
            "content": self.user_input,
            "intent": self.intent.value,
            "entities": self.entities,
            "timestamp": self.timestamp.isoformat()
        }

def conversation_system_demo():
    """æ™ºèƒ½å¯¹è¯ç³»ç»Ÿ"""
    print("\nğŸ’¬ 2. æ™ºèƒ½å¯¹è¯ç³»ç»Ÿ")
    print("=" * 50)

    # AIåˆ†æç”¨æˆ·è¾“å…¥åçš„ç»“æ„åŒ–ç»“æœ
    conversation = ConversationTurn(
        user_input="æˆ‘çš„è®¢å•12345ä¸ºä»€ä¹ˆè¿˜æ²¡å‘è´§ï¼Ÿ",
        intent=DialogState.COMPLAINT,
        entities={
            "order_id": "12345",
            "issue_type": "delivery_delay",
            "urgency": "high"
        },
        response="éå¸¸æŠ±æ­‰ç»™æ‚¨å¸¦æ¥ä¸ä¾¿ï¼Œæˆ‘ç«‹å³ä¸ºæ‚¨æŸ¥è¯¢è®¢å•12345çš„çŠ¶æ€ã€‚"
    )

    print("ğŸ—£ï¸ å¯¹è¯åˆ†æç»“æœ:")
    print(f"ç”¨æˆ·æ„å›¾: {conversation.intent.value}")
    print(f"æå–å®ä½“: {conversation.entities}")
    print(f"èŠå¤©å†å²: {conversation.to_chat_history()}")

# 3. å†…å®¹ç”Ÿæˆå’Œå®¡æ ¸
class ContentGenerationRequest(BaseModel):
    """å†…å®¹ç”Ÿæˆè¯·æ±‚"""
    topic: str = Field(description="ç”Ÿæˆä¸»é¢˜")
    style: str = Field(description="å†™ä½œé£æ ¼", examples=["ä¸“ä¸š", "è½»æ¾", "æ­£å¼"])
    length: str = Field(description="å†…å®¹é•¿åº¦", examples=["short", "medium", "long"])
    keywords: List[str] = Field(description="éœ€è¦åŒ…å«çš„å…³é”®è¯")
    avoid_topics: List[str] = Field(description="éœ€è¦é¿å…çš„è¯é¢˜")

    @field_validator('length')
    def validate_length(cls, v):
        if v not in ['short', 'medium', 'long']:
            raise ValueError('é•¿åº¦å¿…é¡»æ˜¯: short/medium/long')
        return v

class GeneratedContent(BaseModel):
    """ç”Ÿæˆçš„å†…å®¹ç»“æœ"""
    title: str = Field(description="æ ‡é¢˜")
    content: str = Field(description="æ­£æ–‡å†…å®¹")
    quality_score: float = Field(ge=0, le=1, description="è´¨é‡è¯„åˆ†")
    readability_level: str = Field(description="å¯è¯»æ€§çº§åˆ«")
    suggested_improvements: List[str] = Field(description="æ”¹è¿›å»ºè®®")

def content_generation_demo():
    """AIå†…å®¹ç”Ÿæˆ"""
    print("\nğŸ“ 3. AIå†…å®¹ç”Ÿæˆä¸å®¡æ ¸")
    print("=" * 50)

    # å†…å®¹ç”Ÿæˆè¯·æ±‚
    request = ContentGenerationRequest(
        topic="äººå·¥æ™ºèƒ½åœ¨æ•™è‚²ä¸­çš„åº”ç”¨",
        style="ä¸“ä¸š",
        length="medium",
        keywords=["AI", "æ•™è‚²", "ä¸ªæ€§åŒ–å­¦ä¹ ", "æ•™å­¦æ•ˆç‡"],
        avoid_topics=["æ•°æ®éšç§", "å¤±ä¸šé£é™©"]
    )

    # AIç”Ÿæˆçš„å†…å®¹ï¼ˆç»“æ„åŒ–è¾“å‡ºï¼‰
    generated = GeneratedContent(
        title="äººå·¥æ™ºèƒ½å¦‚ä½•å˜é©ç°ä»£æ•™è‚²ä½“ç³»",
        content="AIæŠ€æœ¯é€šè¿‡ä¸ªæ€§åŒ–å­¦ä¹ è·¯å¾„...",
        quality_score=0.88,
        readability_level="å¤§å­¦",
        suggested_improvements=["å¢åŠ å…·ä½“æ¡ˆä¾‹", "è¡¥å……æ•°æ®æ”¯æŒ"]
    )

    print("ğŸ¨ å†…å®¹ç”Ÿæˆè¯·æ±‚:")
    print(f"ä¸»é¢˜: {request.topic}, é£æ ¼: {request.style}")
    print(f"ç”Ÿæˆç»“æœ - è´¨é‡è¯„åˆ†: {generated.quality_score}")
    print(f"æ”¹è¿›å»ºè®®: {generated.suggested_improvements}")

# 4. æ•°æ®æ ‡æ³¨å’Œè®­ç»ƒæ•°æ®ç®¡ç†
class TrainingExample(BaseModel):
    """è®­ç»ƒæ•°æ®æ ·æœ¬"""
    text: str = Field(description="åŸå§‹æ–‡æœ¬")
    labels: Dict[str, Any] = Field(description="æ ‡æ³¨æ ‡ç­¾")
    metadata: Dict[str, Any] = Field(description="å…ƒæ•°æ®")
    created_by: str = Field(description="æ ‡æ³¨äººå‘˜")
    created_at: datetime = Field(default_factory=datetime.now)

    def to_training_format(self, format_type: str = "huggingface"):
        """è½¬æ¢ä¸ºä¸åŒè®­ç»ƒæ¡†æ¶çš„æ ¼å¼"""
        if format_type == "huggingface":
            return {
                "text": self.text,
                "labels": self.labels,
                "metadata": self.metadata
            }
        elif format_type == "spacy":
            return (self.text, {"entities": self.labels})

class DatasetStatistics(BaseModel):
    """æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
    total_examples: int = Field(ge=0, description="æ€»æ ·æœ¬æ•°")
    label_distribution: Dict[str, int] = Field(description="æ ‡ç­¾åˆ†å¸ƒ")
    average_text_length: float = Field(ge=0, description="å¹³å‡æ–‡æœ¬é•¿åº¦")
    data_quality_score: float = Field(ge=0, le=1, description="æ•°æ®è´¨é‡è¯„åˆ†")

def data_annotation_demo():
    """AIæ•°æ®æ ‡æ³¨"""
    print("\nğŸ·ï¸ 4. æ•°æ®æ ‡æ³¨å’Œè®­ç»ƒæ•°æ®ç®¡ç†")
    print("=" * 50)

    # æ ‡æ³¨æ•°æ®æ ·æœ¬
    example = TrainingExample(
        text="è‹¹æœå…¬å¸å‘å¸ƒäº†æ–°æ¬¾iPhoneï¼Œæ­è½½äº†æ›´å¼ºå¤§çš„AIèŠ¯ç‰‡ã€‚",
        labels={
            "entities": {
                "ORG": ["è‹¹æœå…¬å¸"],
                "PRODUCT": ["iPhone", "AIèŠ¯ç‰‡"]
            },
            "sentiment": "positive"
        },
        metadata={"domain": "ç§‘æŠ€", "language": "zh"},
        created_by="annotator_001"
    )

    # æ•°æ®é›†ç»Ÿè®¡
    stats = DatasetStatistics(
        total_examples=10000,
        label_distribution={"positive": 6000, "negative": 3000, "neutral": 1000},
        average_text_length=45.6,
        data_quality_score=0.94
    )

    print("ğŸ“Š è®­ç»ƒæ•°æ®ç®¡ç†:")
    print(f"æ ·æœ¬æ ‡æ³¨: {example.labels}")
    print(f"HuggingFaceæ ¼å¼: {example.to_training_format('huggingface')}")
    print(f"æ•°æ®é›†ç»Ÿè®¡: {stats.total_examples}ä¸ªæ ·æœ¬, è´¨é‡è¯„åˆ†: {stats.data_quality_score}")

# 5. AIè¯„ä¼°å’Œç›‘æ§
class ModelPerformance(BaseModel):
    """æ¨¡å‹æ€§èƒ½è¯„ä¼°"""
    accuracy: float = Field(ge=0, le=1, description="å‡†ç¡®ç‡")
    precision: float = Field(ge=0, le=1, description="ç²¾ç¡®ç‡")
    recall: float = Field(ge=0, le=1, description="å¬å›ç‡")
    f1_score: float = Field(ge=0, le=1, description="F1åˆ†æ•°")
    inference_speed: float = Field(ge=0, description="æ¨ç†é€Ÿåº¦(ms)")

    @property
    def is_production_ready(self):
        """åˆ¤æ–­æ˜¯å¦è¾¾åˆ°ç”Ÿäº§æ ‡å‡†"""
        return self.f1_score > 0.85 and self.inference_speed < 100

class AIPrediction(BaseModel):
    """AIé¢„æµ‹ç»“æœ"""
    input_data: Dict[str, Any] = Field(description="è¾“å…¥æ•°æ®")
    prediction: Any = Field(description="é¢„æµ‹ç»“æœ")
    confidence: float = Field(ge=0, le=1, description="ç½®ä¿¡åº¦")
    model_version: str = Field(description="æ¨¡å‹ç‰ˆæœ¬")
    processing_time: float = Field(ge=0, description="å¤„ç†æ—¶é—´(ç§’)")

def ai_evaluation_demo():
    """AIæ¨¡å‹è¯„ä¼°"""
    print("\nğŸ“ˆ 5. AIæ¨¡å‹è¯„ä¼°å’Œç›‘æ§")
    print("=" * 50)

    # æ¨¡å‹æ€§èƒ½è¯„ä¼°
    performance = ModelPerformance(
        accuracy=0.92,
        precision=0.89,
        recall=0.94,
        f1_score=0.915,
        inference_speed=45.2
    )

    # AIé¢„æµ‹ç»“æœ
    prediction = AIPrediction(
        input_data={"text": "è¿™ä¸ªäº§å“éå¸¸å¥½ç”¨ï¼"},
        prediction="positive",
        confidence=0.96,
        model_version="sentiment-v2.1",
        processing_time=0.12
    )

    print("ğŸ” æ¨¡å‹è¯„ä¼°:")
    print(f"F1åˆ†æ•°: {performance.f1_score}, ç”Ÿäº§å°±ç»ª: {performance.is_production_ready}")
    print(f"é¢„æµ‹ç»“æœ: {prediction.prediction} (ç½®ä¿¡åº¦: {prediction.confidence})")

# 6. ä¸LangChainæ·±åº¦é›†æˆ
class LangChainStructuredOutput(BaseModel):
    """LangChainç»“æ„åŒ–è¾“å‡ºæ¨¡æ¿"""
    analysis: str = Field(description="æ ¸å¿ƒåˆ†æå†…å®¹")
    reasoning: List[str] = Field(description="æ¨ç†è¿‡ç¨‹")
    confidence: float = Field(ge=0, le=1, description="åˆ†æç½®ä¿¡åº¦")
    sources: List[str] = Field(description="å‚è€ƒæ¥æº")
    limitations: List[str] = Field(description="åˆ†æå±€é™æ€§")

    def to_llm_prompt(self):
        """è½¬æ¢ä¸ºLLMæç¤ºè¯æ ¼å¼"""
        return f"""
åˆ†æç»“æœ: {self.analysis}
æ¨ç†è¿‡ç¨‹: {'; '.join(self.reasoning)}
ç½®ä¿¡åº¦: {self.confidence}
å‚è€ƒæ¥æº: {', '.join(self.sources)}
        """.strip()

def langchain_integration_demo():
    """LangChainæ·±åº¦é›†æˆ"""
    print("\nğŸ”— 6. ä¸LangChainæ·±åº¦é›†æˆ")
    print("=" * 50)

    # åœ¨LangChainä¸­ä½¿ç”¨Pydanticç¡®ä¿AIè¾“å‡ºè´¨é‡
    structured_output = LangChainStructuredOutput(
        analysis="è¯¥è¯„è®ºè¡¨è¾¾äº†ç”¨æˆ·å¯¹äº§å“è´¨é‡çš„æ»¡æ„",
        reasoning=[
            "ç”¨æˆ·ä½¿ç”¨äº†'è´¨é‡å¾ˆå¥½'ç­‰æ­£é¢è¯æ±‡",
            "æåˆ°äº†å¤šä¸ªäº§å“ä¼˜ç‚¹",
            "æ²¡æœ‰è´Ÿé¢æƒ…ç»ªè¯æ±‡"
        ],
        confidence=0.93,
        sources=["æƒ…æ„Ÿè¯å…¸", "äº§å“çŸ¥è¯†åº“"],
        limitations=["æ— æ³•ç¡®è®¤ç”¨æˆ·çš„å…·ä½“ä½¿ç”¨åœºæ™¯"]
    )

    print("ğŸš€ LangChainç»“æ„åŒ–è¾“å‡º:")
    print(f"åˆ†æ: {structured_output.analysis}")
    print(f"æ¨ç†æ­¥éª¤: {len(structured_output.reasoning)}ä¸ª")
    print(f"æç¤ºè¯æ ¼å¼:\n{structured_output.to_llm_prompt()}")

if __name__ == "__main__":
    # è¿è¡Œæ‰€æœ‰AIé¢†åŸŸåº”ç”¨æ¼”ç¤º
    ai_structured_output_demo()
    conversation_system_demo()
    content_generation_demo()
    data_annotation_demo()
    ai_evaluation_demo()
    langchain_integration_demo()

    print("\n" + "=" * 60)
    print("ğŸ¯ Pydanticåœ¨AIé¢†åŸŸçš„æ ¸å¿ƒä»·å€¼æ€»ç»“:")
    print("  âœ… ç»“æ„åŒ–AIè¾“å‡º - è®©ä¸å¯é¢„æµ‹çš„æ–‡æœ¬å˜å¯ç¼–ç¨‹æ•°æ®")
    print("  âœ… æ•°æ®è´¨é‡ä¿è¯ - è‡ªåŠ¨éªŒè¯å’Œæ¸…æ´—AIç”Ÿæˆå†…å®¹")
    print("  âœ… è¯„ä¼°å’Œç›‘æ§ - æ ‡å‡†åŒ–æ€§èƒ½æŒ‡æ ‡å’Œé¢„æµ‹ç»“æœ")
    print("  âœ… è®­ç»ƒæ•°æ®ç®¡ç† - ç±»å‹å®‰å…¨çš„æ ‡æ³¨å’Œæ•°æ®ç»Ÿè®¡")
    print("  âœ… ç”Ÿäº§å°±ç»ª - æ„å»ºå¯é çš„ä¼ä¸šçº§AIåº”ç”¨")
    print("  âœ… LangChainé›†æˆ - ç»“æ„åŒ–è¾“å‡ºçš„æ ¸å¿ƒåŸºç¡€è®¾æ–½")
    print("=" * 60)